# Base configuration
OLLAMA_URL=http://localhost:11434
LOG_LEVEL=INFO

EXIT_COMMANDS=exit,quit,bye
RESET_COMMAND=reset

# Model selection (required)
MODELS=deepseek-r1:1.5b,gemma3:1b,SpeakLeash/bielik-11b-v2.3-instruct:Q4_K_M,qwen3:0.6b
JUDGE_MODEL=phi4:latest

# System prompts
#DEFAULT_SYSTEM_PROMPT=Respond naturally and professionally
DEFAULT_SYSTEM_PROMPT=Provide detailed and comprehensive response

QWEN3_SYSTEM_PROMPT=Respond naturally and professionally
DEEPSEEK-R1_SYSTEM_PROMPT=Respond naturally and professionally
GEMMA3_SYSTEM_PROMPT=Respond naturally and professionally
SPEAKLEASH/BIELIK-11B-V2.3-INSTRUCT_SYSTEM_PROMPT=Respond naturally and professionally
PHI4_SYSTEM_PROMPT=Respond naturally and professionally

# Judge evaluation format
JUDGE_USER_QUESTION_PREFIX=User question:
JUDGE_MODEL_RESPONSES_PREFIX=Model responses:
JUDGE_MODEL_RESPONSE_FORMAT=Model {model_name} response:\n{response_content}
JUDGE_SYSTEM_PROMPT=Provide detailed and comprehensive responses
JUDGE_RESPONSE_FORMAT_HEADER=Response format:
JUDGE_RESPONSE_FORMAT_POINTS=1. Brief evaluation of each response\n2. If needed, own improved response
